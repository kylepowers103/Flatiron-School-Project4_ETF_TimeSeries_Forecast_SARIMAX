{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/505) Getting data for MMM...\n",
      "Symbol MMM already downloaded. Skipping...\n",
      "(1/505) Getting data for AOS...\n",
      "Symbol AOS already downloaded. Skipping...\n",
      "(2/505) Getting data for ABT...\n",
      "Symbol ABT already downloaded. Skipping...\n",
      "(3/505) Getting data for ABBV...\n",
      "Symbol ABBV already downloaded. Skipping...\n",
      "(4/505) Getting data for ACN...\n",
      "Symbol ACN already downloaded. Skipping...\n",
      "(5/505) Getting data for ATVI...\n",
      "Symbol ATVI already downloaded. Skipping...\n",
      "(6/505) Getting data for AYI...\n",
      "Symbol AYI already downloaded. Skipping...\n",
      "(7/505) Getting data for ADBE...\n",
      "Symbol ADBE already downloaded. Skipping...\n",
      "(8/505) Getting data for AAP...\n",
      "Symbol AAP already downloaded. Skipping...\n",
      "(9/505) Getting data for AMD...\n",
      "Symbol AMD already downloaded. Skipping...\n",
      "(10/505) Getting data for AES...\n",
      "Symbol AES already downloaded. Skipping...\n",
      "(11/505) Getting data for AET...\n",
      "Symbol AET already downloaded. Skipping...\n",
      "(12/505) Getting data for AMG...\n",
      "Symbol AMG already downloaded. Skipping...\n",
      "(13/505) Getting data for AFL...\n",
      "Symbol AFL already downloaded. Skipping...\n",
      "(14/505) Getting data for A...\n",
      "Symbol A already downloaded. Skipping...\n",
      "(15/505) Getting data for APD...\n",
      "Symbol APD already downloaded. Skipping...\n",
      "(16/505) Getting data for AKAM...\n",
      "Symbol AKAM already downloaded. Skipping...\n",
      "(17/505) Getting data for ALK...\n",
      "Symbol ALK already downloaded. Skipping...\n",
      "(18/505) Getting data for ALB...\n",
      "Symbol ALB already downloaded. Skipping...\n",
      "(19/505) Getting data for ARE...\n",
      "Symbol ARE already downloaded. Skipping...\n",
      "(20/505) Getting data for ALXN...\n",
      "Symbol ALXN already downloaded. Skipping...\n",
      "(21/505) Getting data for ALGN...\n",
      "Symbol ALGN already downloaded. Skipping...\n",
      "(22/505) Getting data for ALLE...\n",
      "Symbol ALLE already downloaded. Skipping...\n",
      "(23/505) Getting data for AGN...\n",
      "Symbol AGN already downloaded. Skipping...\n",
      "(24/505) Getting data for ADS...\n",
      "Symbol ADS already downloaded. Skipping...\n",
      "(25/505) Getting data for LNT...\n",
      "Symbol LNT already downloaded. Skipping...\n",
      "(26/505) Getting data for ALL...\n",
      "Symbol ALL already downloaded. Skipping...\n",
      "(27/505) Getting data for GOOGL...\n",
      "Symbol GOOGL already downloaded. Skipping...\n",
      "(28/505) Getting data for GOOG...\n",
      "Symbol GOOG already downloaded. Skipping...\n",
      "(29/505) Getting data for MO...\n",
      "Symbol MO already downloaded. Skipping...\n",
      "(30/505) Getting data for AMZN...\n",
      "Symbol AMZN already downloaded. Skipping...\n",
      "(31/505) Getting data for AEE...\n",
      "Symbol AEE already downloaded. Skipping...\n",
      "(32/505) Getting data for AAL...\n",
      "Symbol AAL already downloaded. Skipping...\n",
      "(33/505) Getting data for AEP...\n",
      "Symbol AEP already downloaded. Skipping...\n",
      "(34/505) Getting data for AXP...\n",
      "Symbol AXP already downloaded. Skipping...\n",
      "(35/505) Getting data for AIG...\n",
      "Symbol AIG already downloaded. Skipping...\n",
      "(36/505) Getting data for AMT...\n",
      "Symbol AMT already downloaded. Skipping...\n",
      "(37/505) Getting data for AWK...\n",
      "Symbol AWK already downloaded. Skipping...\n",
      "(38/505) Getting data for AMP...\n",
      "Symbol AMP already downloaded. Skipping...\n",
      "(39/505) Getting data for ABC...\n",
      "Symbol ABC already downloaded. Skipping...\n",
      "(40/505) Getting data for AME...\n",
      "Symbol AME already downloaded. Skipping...\n",
      "(41/505) Getting data for AMGN...\n",
      "Symbol AMGN already downloaded. Skipping...\n",
      "(42/505) Getting data for APH...\n",
      "Symbol APH already downloaded. Skipping...\n",
      "(43/505) Getting data for APC...\n",
      "Symbol APC already downloaded. Skipping...\n",
      "(44/505) Getting data for ADI...\n",
      "Symbol ADI already downloaded. Skipping...\n",
      "(45/505) Getting data for ANDV...\n"
     ]
    }
   ],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import ta\n",
    "import time\n",
    "\n",
    "\n",
    "def MA5(df):\n",
    "    return ta.MA(df, 5)\n",
    "\n",
    "\n",
    "def MA10(df):\n",
    "    return ta.MA(df, 10)\n",
    "\n",
    "\n",
    "def EMA20(df):\n",
    "    return ta.EMA(df, 20)\n",
    "\n",
    "\n",
    "def ROC(df):\n",
    "    return ta.ROC(df, 5)\n",
    "\n",
    "\n",
    "def ATR(df):\n",
    "    return ta.ATR(df, 10)\n",
    "\n",
    "\n",
    "def BBANDS(df):\n",
    "    return ta.BBANDS(df, 20)\n",
    "\n",
    "\n",
    "def ADX(df):\n",
    "    return ta.ADX(df, 10, 5)\n",
    "\n",
    "\n",
    "def MACD(df):\n",
    "    return ta.MACD(df, 5, 20)\n",
    "\n",
    "\n",
    "def RSI(df):\n",
    "    return ta.RSI(df, 10)\n",
    "\n",
    "\n",
    "def MFI(df):\n",
    "    return ta.MFI(df, 10)\n",
    "\n",
    "\n",
    "def CCI(df):\n",
    "    return ta.CCI(df, 10)\n",
    "\n",
    "\n",
    "def KELCH(df):\n",
    "    return ta.KELCH(df, 20)\n",
    "\n",
    "\n",
    "indicators = [MA5, MA10, EMA20, ROC, ATR, BBANDS, ta.PPSR, ta.STOK,\n",
    "              ADX, MACD, RSI, MFI, CCI, KELCH]\n",
    "\n",
    "NB_FEATURES = 30\n",
    "\n",
    "API_KEY = '9CRTS3F0KI6FJU95'\n",
    "\n",
    "SYM_FILE = 'S&p500companies.csv'\n",
    "RAW_DATA_DIR = 'raw_data'\n",
    "TRAIN_DATA_DIR = 'data'\n",
    "WINDOW_SIZE = 60\n",
    "\n",
    "TS = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "\n",
    "\n",
    "def get_syms():\n",
    "    syms = []\n",
    "    with open(SYM_FILE) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            syms.append(row[0])\n",
    "    return syms\n",
    "\n",
    "\n",
    "def load_sym(sym):\n",
    "    with open(os.path.join(RAW_DATA_DIR, sym)) as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def split(inputs, window=WINDOW_SIZE):\n",
    "    n = len(inputs)\n",
    "    indices = np.arange(window, n, window)\n",
    "    split_inputs = np.split(inputs[:indices[-2]], indices[:-2])\n",
    "    labels = inputs['Low'].ix[indices[1:]].as_matrix()\\\n",
    "        > inputs['High'].ix[indices[:-1]].as_matrix()\n",
    "    assert len(split_inputs) == len(labels)\n",
    "    return split_inputs, labels\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    data = data.rename(index=str, columns={x: x[3:].capitalize() for x in\n",
    "                                           data.columns})\n",
    "    data['Volume'] = np.log(1 + data['Volume'])\n",
    "    data.index = range(len(data.index))\n",
    "    for indicator in indicators:\n",
    "        data = indicator(data)\n",
    "    data = data.shift(-WINDOW_SIZE)[:-WINDOW_SIZE]\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_all_data_and_save(window=WINDOW_SIZE, nb_features=NB_FEATURES):\n",
    "    all_inputs = []\n",
    "    all_labels = []\n",
    "    for sym in os.listdir(RAW_DATA_DIR):\n",
    "        if sym[0] != '.':\n",
    "            data = load_sym(sym)\n",
    "            if 'data' in data:\n",
    "                inputs = preprocess(data['data'])\n",
    "                if inputs.shape[0] > 2 * window:\n",
    "                    print('Loading data from symbol %s...' % sym)\n",
    "                    inputs, labels = split(inputs, window=window)\n",
    "                    all_inputs.extend(inputs)\n",
    "                    all_labels.append(labels)\n",
    "    all_inputs = np.concatenate(all_inputs).reshape(-1, window, nb_features)\n",
    "    all_labels = np.concatenate(all_labels).reshape(-1, 1)\n",
    "    print(all_inputs.shape)\n",
    "    print(all_labels.shape)\n",
    "    assert all_inputs.shape[0] == all_labels.shape[0]\n",
    "    with open(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_inputs, f)\n",
    "    with open(os.path.join(TRAIN_DATA_DIR, 'all_labels.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_labels, f)\n",
    "    return all_inputs, all_labels\n",
    "\n",
    "\n",
    "def split_train_dev_test_to_file(inputs=None, labels=None):\n",
    "    if inputs is None:\n",
    "        with open(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl'), 'rb') as f:\n",
    "            inputs = pickle.load(f)\n",
    "    if labels is None:\n",
    "        with open(os.path.join(TRAIN_DATA_DIR, 'all_labels.pkl'), 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "    n = inputs.shape[0]\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    indices = np.random.permutation(n)\n",
    "    train_idx, eval_idx, test_idx = \\\n",
    "        indices[:int(0.9*n)], indices[int(0.9*n):int(0.95*n)], \\\n",
    "        indices[int(0.95*n):]\n",
    "    pickle.dump(inputs[train_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'train_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(inputs[eval_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'eval_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(inputs[test_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'test_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(labels[train_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'train_labels.pkl'), 'wb'))\n",
    "    pickle.dump(labels[eval_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'eval_labels.pkl'), 'wb'))\n",
    "    pickle.dump(labels[test_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'test_labels.pkl'), 'wb'))\n",
    "\n",
    "\n",
    "def get_sym_and_save(sym):\n",
    "    if os.path.exists(os.path.join(RAW_DATA_DIR, sym)):\n",
    "        print('Symbol %s already downloaded. Skipping...' % sym)\n",
    "        return\n",
    "    try:\n",
    "        time.sleep(60)\n",
    "        data, metadata = TS.get_daily(symbol=sym, outputsize='full')\n",
    "    except ValueError:\n",
    "        print('Symbol %s does not exist! Skipping...' % sym)\n",
    "        with open(os.path.join(RAW_DATA_DIR, sym), 'wb') as f:\n",
    "            pickle.dump({}, f)\n",
    "        return\n",
    "    with open(os.path.join(RAW_DATA_DIR, sym), 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'data': data,\n",
    "            'metadata': metadata\n",
    "        }, f)\n",
    "\n",
    "\n",
    "def get_all_raw_data(interval='5min'):\n",
    "    syms = get_syms()\n",
    "    for i, sym in enumerate(syms):\n",
    "        print('(%d/%d) Getting data for %s...' % (i, len(syms), sym))\n",
    "        get_sym_and_save(sym)\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl')) \\\n",
    "            or not os.path.exists(os.path.join(TRAIN_DATA_DIR,\n",
    "                                               'all_labels.pkl')):\n",
    "        get_all_raw_data()\n",
    "        split_all_data_and_save()\n",
    "    split_train_dev_test_to_file()\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = data.rename(index=str, columns={x: x[3:].capitalize() for x in\n",
    "                                           data.columns})\n",
    "    data['Volume'] = np.log(1 + data['Volume'])\n",
    "    data.index = range(len(data.index))\n",
    "    for indicator in indicators:\n",
    "        data = indicator(data)\n",
    "    data = data.shift(-WINDOW_SIZE)[:-WINDOW_SIZE]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Volume'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Volume'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-095cf75a5481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-dcad2a459779>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m     data = data.rename(index=str, columns={x: x[3:].capitalize() for x in\n\u001b[1;32m      3\u001b[0m                                            data.columns})\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindicators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Volume'"
     ]
    }
   ],
   "source": [
    "# preprocess(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
