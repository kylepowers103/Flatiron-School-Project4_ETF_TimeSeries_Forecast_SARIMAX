{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data':             1. open  2. high   3. low  4. close   5. volume\n",
       " date                                                       \n",
       " 1998-01-02    63.56   63.620  62.5600     63.12    202600.0\n",
       " 1998-01-05    63.00   63.190  62.5600     62.94    258100.0\n",
       " 1998-01-06    62.69   62.750  62.0000     62.25    302800.0\n",
       " 1998-01-07    62.00   62.000  60.5000     61.38    313300.0\n",
       " 1998-01-08    61.38   61.380  59.8100     60.38    253500.0\n",
       " 1998-01-09    60.00   60.380  59.4400     59.56    491500.0\n",
       " 1998-01-12    58.00   59.190  58.0000     59.00    400200.0\n",
       " 1998-01-13    59.00   60.000  58.9400     59.81    182600.0\n",
       " 1998-01-14    59.94   60.190  59.5000     60.19    158100.0\n",
       " 1998-01-15    60.00   60.310  59.5000     59.50    155200.0\n",
       " 1998-01-16    59.50   59.810  59.4400     59.56    247300.0\n",
       " 1998-01-20    59.56   60.000  59.5600     60.00    223800.0\n",
       " 1998-01-21    60.00   60.000  58.7500     59.19    156700.0\n",
       " 1998-01-22    59.00   59.000  58.1200     58.44    200700.0\n",
       " 1998-01-23    58.62   58.810  57.8800     58.06    186100.0\n",
       " 1998-01-26    58.19   58.940  58.0000     58.31    131800.0\n",
       " 1998-01-27    58.25   59.250  58.2500     58.88    174100.0\n",
       " 1998-01-28    59.12   59.500  58.5000     59.50    161900.0\n",
       " 1998-01-29    59.00   60.250  59.0000     59.50    197400.0\n",
       " 1998-01-30    59.50   59.500  58.7500     58.94    152500.0\n",
       " 1998-02-02    59.56   60.250  59.5600     60.25    273600.0\n",
       " 1998-02-03    60.25   60.940  59.6900     60.94    136600.0\n",
       " 1998-02-04    60.69   60.690  59.8800     60.12    328600.0\n",
       " 1998-02-05    60.25   60.380  59.4400     60.19    124200.0\n",
       " 1998-02-06    60.38   61.940  60.3800     61.88    217300.0\n",
       " 1998-02-09    61.75   61.940  61.1900     61.94    133000.0\n",
       " 1998-02-10    61.94   62.440  61.9400     62.12    164600.0\n",
       " 1998-02-11    62.12   62.310  61.7500     62.00     75900.0\n",
       " 1998-02-12    61.81   62.060  61.2500     61.88    126100.0\n",
       " 1998-02-13    61.88   62.310  61.8800     62.06    111000.0\n",
       " ...             ...      ...      ...       ...         ...\n",
       " 2018-12-06    47.56   48.180  46.9100     48.14   6818633.0\n",
       " 2018-12-07    48.15   48.670  47.3200     47.66   5524530.0\n",
       " 2018-12-10    47.60   47.660  46.2500     46.95   5942833.0\n",
       " 2018-12-11    47.31   47.685  46.2600     46.56   4734211.0\n",
       " 2018-12-12    47.10   47.370  46.6600     46.82   4394718.0\n",
       " 2018-12-13    46.92   47.015  45.8000     46.02   4718687.0\n",
       " 2018-12-14    45.69   46.400  45.5850     45.66   5380992.0\n",
       " 2018-12-17    45.43   45.955  44.9400     45.15   4858977.0\n",
       " 2018-12-18    45.24   45.470  43.8928     44.16   5398224.0\n",
       " 2018-12-19    44.01   44.500  42.9600     43.30   6380711.0\n",
       " 2018-12-20    42.78   43.550  42.7100     43.19   7860421.0\n",
       " 2018-12-21    42.88   43.730  42.2600     42.38   9199049.0\n",
       " 2018-12-24    42.07   42.420  41.2500     41.27   3378956.0\n",
       " 2018-12-26    41.28   42.830  40.6800     42.83   5577547.0\n",
       " 2018-12-27    42.31   42.980  41.4800     42.98   6295508.0\n",
       " 2018-12-28    43.11   43.490  42.6100     42.95   4593560.0\n",
       " 2018-12-31    43.01   43.450  42.6400     43.32   3694095.0\n",
       " 2019-01-02    42.86   44.450  42.7900     44.39   4831912.0\n",
       " 2019-01-03    44.22   44.790  43.9600     44.09   3530604.0\n",
       " 2019-01-04    44.87   45.420  44.7000     45.25   3267164.0\n",
       " 2019-01-07    45.13   46.040  44.8600     45.61   3584381.0\n",
       " 2019-01-08    45.79   45.960  45.0700     45.72   3389345.0\n",
       " 2019-01-09    45.84   46.290  45.6200     46.15   5826951.0\n",
       " 2019-01-10    45.20   46.140  45.2000     45.86   6726848.0\n",
       " 2019-01-11    44.83   45.760  44.7800     45.61  11337051.0\n",
       " 2019-01-14    45.20   46.350  45.2000     46.15   9035417.0\n",
       " 2019-01-15    46.02   46.390  45.5400     46.34   6512927.0\n",
       " 2019-01-16    46.78   47.845  46.5600     47.54   7020043.0\n",
       " 2019-01-17    46.75   48.450  46.5500     48.28   5811600.0\n",
       " 2019-01-18    48.49   49.410  48.1900     49.29   5214575.0\n",
       " \n",
       " [5296 rows x 5 columns],\n",
       " 'metadata': {'1. Information': 'Daily Prices (open, high, low, close) and Volumes',\n",
       "  '2. Symbol': 'BBT',\n",
       "  '3. Last Refreshed': '2019-01-18',\n",
       "  '4. Output Size': 'Full size',\n",
       "  '5. Time Zone': 'US/Eastern'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import argparse\n",
    "import quandl\n",
    "import pandas_datareader as web\n",
    "from time import sleep\n",
    "import datetime as dt\n",
    "import sys\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.techindicators import TechIndicators\n",
    "from alpha_vantage.sectorperformance import SectorPerformances\n",
    "from alpha_vantage.cryptocurrencies import CryptoCurrencies\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "RAW_DATA_DIR = 'raw_data'\n",
    "def load_dataset_from_disk(save_dir):\n",
    "    with open(os.path.join(save_dir, \"BBT\"), 'rb') as f:\n",
    "        transformers = pickle.load(f)\n",
    "    return transformers\n",
    "\n",
    "carl=load_dataset_from_disk(RAW_DATA_DIR)\n",
    "carl.keys() #(['data', 'metadata'])\n",
    "carl[\"data\"]\n",
    "# carl[\"metadata\"][]\n",
    "carl[\"metadata\"].keys()\n",
    "carl[\"metadata\"]\n",
    "carl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/505) Getting data for MMM...\n",
      "Symbol MMM already downloaded. Skipping...\n",
      "(1/505) Getting data for AOS...\n",
      "Symbol AOS already downloaded. Skipping...\n",
      "(2/505) Getting data for ABT...\n",
      "Symbol ABT already downloaded. Skipping...\n",
      "(3/505) Getting data for ABBV...\n",
      "Symbol ABBV already downloaded. Skipping...\n",
      "(4/505) Getting data for ACN...\n",
      "Symbol ACN already downloaded. Skipping...\n",
      "(5/505) Getting data for ATVI...\n",
      "Symbol ATVI already downloaded. Skipping...\n",
      "(6/505) Getting data for AYI...\n",
      "Symbol AYI already downloaded. Skipping...\n",
      "(7/505) Getting data for ADBE...\n",
      "Symbol ADBE already downloaded. Skipping...\n",
      "(8/505) Getting data for AAP...\n",
      "Symbol AAP already downloaded. Skipping...\n",
      "(9/505) Getting data for AMD...\n",
      "Symbol AMD already downloaded. Skipping...\n",
      "(10/505) Getting data for AES...\n",
      "Symbol AES already downloaded. Skipping...\n",
      "(11/505) Getting data for AET...\n",
      "Symbol AET already downloaded. Skipping...\n",
      "(12/505) Getting data for AMG...\n",
      "Symbol AMG already downloaded. Skipping...\n",
      "(13/505) Getting data for AFL...\n",
      "Symbol AFL already downloaded. Skipping...\n",
      "(14/505) Getting data for A...\n",
      "Symbol A already downloaded. Skipping...\n",
      "(15/505) Getting data for APD...\n",
      "Symbol APD already downloaded. Skipping...\n",
      "(16/505) Getting data for AKAM...\n",
      "Symbol AKAM already downloaded. Skipping...\n",
      "(17/505) Getting data for ALK...\n",
      "Symbol ALK already downloaded. Skipping...\n",
      "(18/505) Getting data for ALB...\n",
      "Symbol ALB already downloaded. Skipping...\n",
      "(19/505) Getting data for ARE...\n",
      "Symbol ARE already downloaded. Skipping...\n",
      "(20/505) Getting data for ALXN...\n",
      "Symbol ALXN already downloaded. Skipping...\n",
      "(21/505) Getting data for ALGN...\n",
      "Symbol ALGN already downloaded. Skipping...\n",
      "(22/505) Getting data for ALLE...\n",
      "Symbol ALLE already downloaded. Skipping...\n",
      "(23/505) Getting data for AGN...\n",
      "Symbol AGN already downloaded. Skipping...\n",
      "(24/505) Getting data for ADS...\n",
      "Symbol ADS already downloaded. Skipping...\n",
      "(25/505) Getting data for LNT...\n",
      "Symbol LNT already downloaded. Skipping...\n",
      "(26/505) Getting data for ALL...\n",
      "Symbol ALL already downloaded. Skipping...\n",
      "(27/505) Getting data for GOOGL...\n",
      "Symbol GOOGL already downloaded. Skipping...\n",
      "(28/505) Getting data for GOOG...\n",
      "Symbol GOOG already downloaded. Skipping...\n",
      "(29/505) Getting data for MO...\n",
      "Symbol MO already downloaded. Skipping...\n",
      "(30/505) Getting data for AMZN...\n",
      "Symbol AMZN already downloaded. Skipping...\n",
      "(31/505) Getting data for AEE...\n",
      "Symbol AEE already downloaded. Skipping...\n",
      "(32/505) Getting data for AAL...\n",
      "Symbol AAL already downloaded. Skipping...\n",
      "(33/505) Getting data for AEP...\n",
      "Symbol AEP already downloaded. Skipping...\n",
      "(34/505) Getting data for AXP...\n",
      "Symbol AXP already downloaded. Skipping...\n",
      "(35/505) Getting data for AIG...\n",
      "Symbol AIG already downloaded. Skipping...\n",
      "(36/505) Getting data for AMT...\n",
      "Symbol AMT already downloaded. Skipping...\n",
      "(37/505) Getting data for AWK...\n",
      "Symbol AWK already downloaded. Skipping...\n",
      "(38/505) Getting data for AMP...\n",
      "Symbol AMP already downloaded. Skipping...\n",
      "(39/505) Getting data for ABC...\n",
      "Symbol ABC already downloaded. Skipping...\n",
      "(40/505) Getting data for AME...\n",
      "Symbol AME already downloaded. Skipping...\n",
      "(41/505) Getting data for AMGN...\n",
      "Symbol AMGN already downloaded. Skipping...\n",
      "(42/505) Getting data for APH...\n",
      "Symbol APH already downloaded. Skipping...\n",
      "(43/505) Getting data for APC...\n",
      "Symbol APC already downloaded. Skipping...\n",
      "(44/505) Getting data for ADI...\n",
      "Symbol ADI already downloaded. Skipping...\n",
      "(45/505) Getting data for ANDV...\n",
      "Symbol ANDV already downloaded. Skipping...\n",
      "(46/505) Getting data for ANSS...\n",
      "Symbol ANSS already downloaded. Skipping...\n",
      "(47/505) Getting data for ANTM...\n",
      "Symbol ANTM already downloaded. Skipping...\n",
      "(48/505) Getting data for AON...\n",
      "Symbol AON already downloaded. Skipping...\n",
      "(49/505) Getting data for APA...\n",
      "Symbol APA already downloaded. Skipping...\n",
      "(50/505) Getting data for AIV...\n",
      "Symbol AIV already downloaded. Skipping...\n",
      "(51/505) Getting data for AAPL...\n",
      "Symbol AAPL already downloaded. Skipping...\n",
      "(52/505) Getting data for AMAT...\n",
      "Symbol AMAT already downloaded. Skipping...\n",
      "(53/505) Getting data for APTV...\n",
      "Symbol APTV already downloaded. Skipping...\n",
      "(54/505) Getting data for ADM...\n",
      "Symbol ADM already downloaded. Skipping...\n",
      "(55/505) Getting data for ARNC...\n",
      "Symbol ARNC already downloaded. Skipping...\n",
      "(56/505) Getting data for AJG...\n",
      "Symbol AJG already downloaded. Skipping...\n",
      "(57/505) Getting data for AIZ...\n",
      "Symbol AIZ already downloaded. Skipping...\n",
      "(58/505) Getting data for T...\n",
      "Symbol T already downloaded. Skipping...\n",
      "(59/505) Getting data for ADSK...\n",
      "Symbol ADSK already downloaded. Skipping...\n",
      "(60/505) Getting data for ADP...\n",
      "Symbol ADP already downloaded. Skipping...\n",
      "(61/505) Getting data for AZO...\n",
      "Symbol AZO already downloaded. Skipping...\n",
      "(62/505) Getting data for AVB...\n",
      "Symbol AVB already downloaded. Skipping...\n",
      "(63/505) Getting data for AVY...\n",
      "Symbol AVY already downloaded. Skipping...\n",
      "(64/505) Getting data for BHGE...\n",
      "Symbol BHGE already downloaded. Skipping...\n",
      "(65/505) Getting data for BLL...\n",
      "Symbol BLL already downloaded. Skipping...\n",
      "(66/505) Getting data for BAC...\n",
      "Symbol BAC already downloaded. Skipping...\n",
      "(67/505) Getting data for BAX...\n",
      "Symbol BAX already downloaded. Skipping...\n",
      "(68/505) Getting data for BBT...\n",
      "Symbol BBT already downloaded. Skipping...\n",
      "(69/505) Getting data for BDX...\n",
      "Symbol BDX already downloaded. Skipping...\n",
      "(70/505) Getting data for BRK.B...\n",
      "Symbol BRK.B already downloaded. Skipping...\n",
      "(71/505) Getting data for BBY...\n",
      "Symbol BBY already downloaded. Skipping...\n",
      "(72/505) Getting data for BIIB...\n",
      "Symbol BIIB already downloaded. Skipping...\n",
      "(73/505) Getting data for BLK...\n",
      "Symbol BLK already downloaded. Skipping...\n",
      "(74/505) Getting data for HRB...\n",
      "Symbol HRB already downloaded. Skipping...\n",
      "(75/505) Getting data for BA...\n",
      "Symbol BA already downloaded. Skipping...\n",
      "(76/505) Getting data for BKNG...\n",
      "Symbol BKNG already downloaded. Skipping...\n",
      "(77/505) Getting data for BWA...\n",
      "Symbol BWA already downloaded. Skipping...\n",
      "(78/505) Getting data for BXP...\n",
      "Symbol BXP already downloaded. Skipping...\n",
      "(79/505) Getting data for BSX...\n",
      "Symbol BSX already downloaded. Skipping...\n",
      "(80/505) Getting data for BHF...\n",
      "Symbol BHF already downloaded. Skipping...\n",
      "(81/505) Getting data for BMY...\n",
      "Symbol BMY already downloaded. Skipping...\n",
      "(82/505) Getting data for AVGO...\n",
      "Symbol AVGO already downloaded. Skipping...\n",
      "(83/505) Getting data for BF.B...\n",
      "Symbol BF.B already downloaded. Skipping...\n",
      "(84/505) Getting data for CHRW...\n",
      "Symbol CHRW already downloaded. Skipping...\n",
      "(85/505) Getting data for CA...\n",
      "Symbol CA already downloaded. Skipping...\n",
      "(86/505) Getting data for COG...\n",
      "Symbol COG already downloaded. Skipping...\n",
      "(87/505) Getting data for CDNS...\n",
      "Symbol CDNS already downloaded. Skipping...\n",
      "(88/505) Getting data for CPB...\n",
      "Symbol CPB already downloaded. Skipping...\n",
      "(89/505) Getting data for COF...\n",
      "Symbol COF already downloaded. Skipping...\n",
      "(90/505) Getting data for CAH...\n",
      "Symbol CAH already downloaded. Skipping...\n",
      "(91/505) Getting data for KMX...\n",
      "Symbol KMX already downloaded. Skipping...\n",
      "(92/505) Getting data for CCL...\n",
      "Symbol CCL already downloaded. Skipping...\n",
      "(93/505) Getting data for CAT...\n",
      "Symbol CAT already downloaded. Skipping...\n",
      "(94/505) Getting data for CBOE...\n",
      "Symbol CBOE already downloaded. Skipping...\n",
      "(95/505) Getting data for CBRE...\n",
      "Symbol CBRE already downloaded. Skipping...\n",
      "(96/505) Getting data for CBS...\n",
      "Symbol CBS already downloaded. Skipping...\n",
      "(97/505) Getting data for CELG...\n",
      "Symbol CELG already downloaded. Skipping...\n",
      "(98/505) Getting data for CNC...\n",
      "Symbol CNC already downloaded. Skipping...\n",
      "(99/505) Getting data for CNP...\n",
      "Symbol CNP already downloaded. Skipping...\n",
      "(100/505) Getting data for CTL...\n",
      "Symbol CTL already downloaded. Skipping...\n",
      "(101/505) Getting data for CERN...\n",
      "Symbol CERN already downloaded. Skipping...\n",
      "(102/505) Getting data for CF...\n",
      "Symbol CF already downloaded. Skipping...\n",
      "(103/505) Getting data for SCHW...\n",
      "Symbol SCHW already downloaded. Skipping...\n",
      "(104/505) Getting data for CHTR...\n",
      "Symbol CHTR already downloaded. Skipping...\n",
      "(105/505) Getting data for CVX...\n",
      "Symbol CVX already downloaded. Skipping...\n",
      "(106/505) Getting data for CMG...\n",
      "Symbol CMG already downloaded. Skipping...\n",
      "(107/505) Getting data for CB...\n",
      "Symbol CB already downloaded. Skipping...\n",
      "(108/505) Getting data for CHD...\n",
      "Symbol CHD already downloaded. Skipping...\n",
      "(109/505) Getting data for CI...\n",
      "Symbol CI already downloaded. Skipping...\n",
      "(110/505) Getting data for XEC...\n",
      "Symbol XEC already downloaded. Skipping...\n",
      "(111/505) Getting data for CINF...\n",
      "Symbol CINF already downloaded. Skipping...\n",
      "(112/505) Getting data for CTAS...\n",
      "Symbol CTAS already downloaded. Skipping...\n",
      "(113/505) Getting data for CSCO...\n",
      "Symbol CSCO already downloaded. Skipping...\n",
      "(114/505) Getting data for C...\n",
      "Symbol C already downloaded. Skipping...\n",
      "(115/505) Getting data for CFG...\n",
      "Symbol CFG already downloaded. Skipping...\n",
      "(116/505) Getting data for CTXS...\n",
      "Symbol CTXS already downloaded. Skipping...\n",
      "(117/505) Getting data for CME...\n",
      "Symbol CME already downloaded. Skipping...\n",
      "(118/505) Getting data for CMS...\n",
      "Symbol CMS already downloaded. Skipping...\n",
      "(119/505) Getting data for KO...\n",
      "Symbol KO already downloaded. Skipping...\n",
      "(120/505) Getting data for CTSH...\n",
      "Symbol CTSH already downloaded. Skipping...\n",
      "(121/505) Getting data for CL...\n",
      "Symbol CL already downloaded. Skipping...\n",
      "(122/505) Getting data for CMCSA...\n",
      "Symbol CMCSA already downloaded. Skipping...\n",
      "(123/505) Getting data for CMA...\n",
      "Symbol CMA already downloaded. Skipping...\n",
      "(124/505) Getting data for CAG...\n",
      "Symbol CAG already downloaded. Skipping...\n",
      "(125/505) Getting data for CXO...\n",
      "Symbol CXO already downloaded. Skipping...\n",
      "(126/505) Getting data for COP...\n",
      "Symbol COP already downloaded. Skipping...\n",
      "(127/505) Getting data for ED...\n",
      "Symbol ED already downloaded. Skipping...\n",
      "(128/505) Getting data for STZ...\n",
      "Symbol STZ already downloaded. Skipping...\n",
      "(129/505) Getting data for GLW...\n",
      "Symbol GLW already downloaded. Skipping...\n",
      "(130/505) Getting data for COST...\n",
      "Symbol COST already downloaded. Skipping...\n",
      "(131/505) Getting data for COTY...\n",
      "Symbol COTY already downloaded. Skipping...\n",
      "(132/505) Getting data for CCI...\n",
      "Symbol CCI already downloaded. Skipping...\n",
      "(133/505) Getting data for CSRA...\n",
      "Symbol CSRA already downloaded. Skipping...\n",
      "(134/505) Getting data for CSX...\n",
      "Symbol CSX already downloaded. Skipping...\n",
      "(135/505) Getting data for CMI...\n",
      "Symbol CMI already downloaded. Skipping...\n",
      "(136/505) Getting data for CVS...\n",
      "Symbol CVS already downloaded. Skipping...\n",
      "(137/505) Getting data for DHI...\n",
      "Symbol DHI already downloaded. Skipping...\n",
      "(138/505) Getting data for DHR...\n",
      "Symbol DHR already downloaded. Skipping...\n",
      "(139/505) Getting data for DRI...\n",
      "Symbol DRI already downloaded. Skipping...\n",
      "(140/505) Getting data for DVA...\n",
      "Symbol DVA already downloaded. Skipping...\n",
      "(141/505) Getting data for DE...\n",
      "Symbol DE already downloaded. Skipping...\n",
      "(142/505) Getting data for DAL...\n",
      "Symbol DAL already downloaded. Skipping...\n",
      "(143/505) Getting data for XRAY...\n",
      "Symbol XRAY already downloaded. Skipping...\n",
      "(144/505) Getting data for DVN...\n",
      "Symbol DVN already downloaded. Skipping...\n",
      "(145/505) Getting data for DLR...\n",
      "Symbol DLR already downloaded. Skipping...\n",
      "(146/505) Getting data for DFS...\n",
      "Symbol DFS already downloaded. Skipping...\n",
      "(147/505) Getting data for DISCA...\n",
      "Symbol DISCA already downloaded. Skipping...\n",
      "(148/505) Getting data for DISCK...\n",
      "Symbol DISCK already downloaded. Skipping...\n",
      "(149/505) Getting data for DISH...\n",
      "Symbol DISH already downloaded. Skipping...\n",
      "(150/505) Getting data for DG...\n",
      "Symbol DG already downloaded. Skipping...\n",
      "(151/505) Getting data for DLTR...\n",
      "Symbol DLTR already downloaded. Skipping...\n",
      "(152/505) Getting data for D...\n",
      "Symbol D already downloaded. Skipping...\n",
      "(153/505) Getting data for DOV...\n",
      "Symbol DOV already downloaded. Skipping...\n",
      "(154/505) Getting data for DWDP...\n",
      "Symbol DWDP already downloaded. Skipping...\n",
      "(155/505) Getting data for DPS...\n",
      "Symbol DPS already downloaded. Skipping...\n",
      "(156/505) Getting data for DTE...\n",
      "Symbol DTE already downloaded. Skipping...\n",
      "(157/505) Getting data for DUK...\n",
      "Symbol DUK already downloaded. Skipping...\n",
      "(158/505) Getting data for DRE...\n",
      "Symbol DRE already downloaded. Skipping...\n",
      "(159/505) Getting data for DXC...\n",
      "Symbol DXC already downloaded. Skipping...\n",
      "(160/505) Getting data for ETFC...\n",
      "Symbol ETFC already downloaded. Skipping...\n",
      "(161/505) Getting data for EMN...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162/505) Getting data for ETN...\n",
      "(163/505) Getting data for EBAY...\n",
      "(164/505) Getting data for ECL...\n",
      "(165/505) Getting data for EIX...\n",
      "(166/505) Getting data for EW...\n",
      "(167/505) Getting data for EA...\n",
      "(168/505) Getting data for EMR...\n",
      "(169/505) Getting data for ETR...\n",
      "(170/505) Getting data for EVHC...\n"
     ]
    }
   ],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import ta\n",
    "import time\n",
    "\n",
    "\n",
    "def MA5(df):\n",
    "    return ta.MA(df, 5)\n",
    "\n",
    "\n",
    "def MA10(df):\n",
    "    return ta.MA(df, 10)\n",
    "\n",
    "\n",
    "def EMA20(df):\n",
    "    return ta.EMA(df, 20)\n",
    "\n",
    "\n",
    "def ROC(df):\n",
    "    return ta.ROC(df, 5)\n",
    "\n",
    "\n",
    "def ATR(df):\n",
    "    return ta.ATR(df, 10)\n",
    "\n",
    "\n",
    "def BBANDS(df):\n",
    "    return ta.BBANDS(df, 20)\n",
    "\n",
    "\n",
    "def ADX(df):\n",
    "    return ta.ADX(df, 10, 5)\n",
    "\n",
    "\n",
    "def MACD(df):\n",
    "    return ta.MACD(df, 5, 20)\n",
    "\n",
    "\n",
    "def RSI(df):\n",
    "    return ta.RSI(df, 10)\n",
    "\n",
    "\n",
    "def MFI(df):\n",
    "    return ta.MFI(df, 10)\n",
    "\n",
    "\n",
    "def CCI(df):\n",
    "    return ta.CCI(df, 10)\n",
    "\n",
    "\n",
    "def KELCH(df):\n",
    "    return ta.KELCH(df, 20)\n",
    "\n",
    "\n",
    "indicators = [MA5, MA10, EMA20, ROC, ATR, BBANDS, ta.PPSR, ta.STOK,\n",
    "              ADX, MACD, RSI, MFI, CCI, KELCH]\n",
    "\n",
    "NB_FEATURES = 30\n",
    "\n",
    "API_KEY = 'TZZ9RPNH9YGP8SXX'\n",
    "# Your premium API key for 30 API calls per minute is: TZZ9RPNH9YGP8SXX\n",
    "\n",
    "SYM_FILE = 'S&p500companies.csv'\n",
    "RAW_DATA_DIR = 'raw_data'\n",
    "TRAIN_DATA_DIR = 'data'\n",
    "WINDOW_SIZE = 60\n",
    "\n",
    "TS = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "\n",
    "\n",
    "def get_syms():\n",
    "    syms = []\n",
    "    with open(SYM_FILE) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            syms.append(row[0])\n",
    "    return syms\n",
    "\n",
    "\n",
    "def load_sym(sym):\n",
    "    with open(os.path.join(RAW_DATA_DIR, sym)) as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def split(inputs, window=WINDOW_SIZE):\n",
    "    n = len(inputs)\n",
    "    indices = np.arange(window, n, window)\n",
    "    split_inputs = np.split(inputs[:indices[-2]], indices[:-2])\n",
    "    labels = inputs['Low'].ix[indices[1:]].as_matrix()\\\n",
    "        > inputs['High'].ix[indices[:-1]].as_matrix()\n",
    "    assert len(split_inputs) == len(labels)\n",
    "    return split_inputs, labels\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    data = data.rename(index=str, columns={x: x[3:].capitalize() for x in\n",
    "                                           data.columns})\n",
    "    data['Volume'] = np.log(1 + data['Volume'])\n",
    "    data.index = range(len(data.index))\n",
    "    for indicator in indicators:\n",
    "        data = indicator(data)\n",
    "    data = data.shift(-WINDOW_SIZE)[:-WINDOW_SIZE]\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_all_data_and_save(window=WINDOW_SIZE, nb_features=NB_FEATURES):\n",
    "    all_inputs = []\n",
    "    all_labels = []\n",
    "    for sym in os.listdir(RAW_DATA_DIR):\n",
    "        if sym[0] != '.':\n",
    "            data = load_sym(sym)\n",
    "            if 'data' in data:\n",
    "                inputs = preprocess(data['data'])\n",
    "                if inputs.shape[0] > 2 * window:\n",
    "                    print('Loading data from symbol %s...' % sym)\n",
    "                    inputs, labels = split(inputs, window=window)\n",
    "                    all_inputs.extend(inputs)\n",
    "                    all_labels.append(labels)\n",
    "    all_inputs = np.concatenate(all_inputs).reshape(-1, window, nb_features)\n",
    "    all_labels = np.concatenate(all_labels).reshape(-1, 1)\n",
    "    print(all_inputs.shape)\n",
    "    print(all_labels.shape)\n",
    "    assert all_inputs.shape[0] == all_labels.shape[0]\n",
    "    with open(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_inputs, f)\n",
    "    with open(os.path.join(TRAIN_DATA_DIR, 'all_labels.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_labels, f)\n",
    "    return all_inputs, all_labels\n",
    "\n",
    "\n",
    "def split_train_dev_test_to_file(inputs=None, labels=None):\n",
    "    if inputs is None:\n",
    "        with open(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl'), 'rb') as f:\n",
    "            inputs = pickle.load(f)\n",
    "    if labels is None:\n",
    "        with open(os.path.join(TRAIN_DATA_DIR, 'all_labels.pkl'), 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "    n = inputs.shape[0]\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    indices = np.random.permutation(n)\n",
    "    train_idx, eval_idx, test_idx = \\\n",
    "        indices[:int(0.9*n)], indices[int(0.9*n):int(0.95*n)], \\\n",
    "        indices[int(0.95*n):]\n",
    "    pickle.dump(inputs[train_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'train_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(inputs[eval_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'eval_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(inputs[test_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'test_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(labels[train_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'train_labels.pkl'), 'wb'))\n",
    "    pickle.dump(labels[eval_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'eval_labels.pkl'), 'wb'))\n",
    "    pickle.dump(labels[test_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'test_labels.pkl'), 'wb'))\n",
    "\n",
    "\n",
    "def get_sym_and_save(sym):\n",
    "    if os.path.exists(os.path.join(RAW_DATA_DIR, sym)):\n",
    "        print('Symbol %s already downloaded. Skipping...' % sym)\n",
    "        return\n",
    "    try:\n",
    "        data, metadata = TS.get_daily(symbol=sym, outputsize='full')\n",
    "#         time.sleep(10)\n",
    "    except ValueError:\n",
    "        print('Symbol %s does not exist! Skipping...' % sym)\n",
    "        with open(os.path.join(RAW_DATA_DIR, sym), 'wb') as f:\n",
    "            pickle.dump({}, f)\n",
    "        return\n",
    "    with open(os.path.join(RAW_DATA_DIR, sym), 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'data': data,\n",
    "            'metadata': metadata\n",
    "        }, f)\n",
    "\n",
    "\n",
    "def get_all_raw_data(interval='5min'):\n",
    "    syms = get_syms()\n",
    "    for i, sym in enumerate(syms):\n",
    "        print('(%d/%d) Getting data for %s...' % (i, len(syms), sym))\n",
    "        get_sym_and_save(sym)\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl')) \\\n",
    "            or not os.path.exists(os.path.join(TRAIN_DATA_DIR,\n",
    "                                               'all_labels.pkl')):\n",
    "        get_all_raw_data()\n",
    "        split_all_data_and_save()\n",
    "    split_train_dev_test_to_file()\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = data.rename(index=str, columns={x: x[3:].capitalize() for x in\n",
    "                                           data.columns})\n",
    "    data['Volume'] = np.log(1 + data['Volume'])\n",
    "    data.index = range(len(data.index))\n",
    "    for indicator in indicators:\n",
    "        data = indicator(data)\n",
    "    data = data.shift(-WINDOW_SIZE)[:-WINDOW_SIZE]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
