{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data':             1. open  2. high   3. low  4. close   5. volume\n",
       " date                                                       \n",
       " 1998-01-02    63.56   63.620  62.5600     63.12    202600.0\n",
       " 1998-01-05    63.00   63.190  62.5600     62.94    258100.0\n",
       " 1998-01-06    62.69   62.750  62.0000     62.25    302800.0\n",
       " 1998-01-07    62.00   62.000  60.5000     61.38    313300.0\n",
       " 1998-01-08    61.38   61.380  59.8100     60.38    253500.0\n",
       " 1998-01-09    60.00   60.380  59.4400     59.56    491500.0\n",
       " 1998-01-12    58.00   59.190  58.0000     59.00    400200.0\n",
       " 1998-01-13    59.00   60.000  58.9400     59.81    182600.0\n",
       " 1998-01-14    59.94   60.190  59.5000     60.19    158100.0\n",
       " 1998-01-15    60.00   60.310  59.5000     59.50    155200.0\n",
       " 1998-01-16    59.50   59.810  59.4400     59.56    247300.0\n",
       " 1998-01-20    59.56   60.000  59.5600     60.00    223800.0\n",
       " 1998-01-21    60.00   60.000  58.7500     59.19    156700.0\n",
       " 1998-01-22    59.00   59.000  58.1200     58.44    200700.0\n",
       " 1998-01-23    58.62   58.810  57.8800     58.06    186100.0\n",
       " 1998-01-26    58.19   58.940  58.0000     58.31    131800.0\n",
       " 1998-01-27    58.25   59.250  58.2500     58.88    174100.0\n",
       " 1998-01-28    59.12   59.500  58.5000     59.50    161900.0\n",
       " 1998-01-29    59.00   60.250  59.0000     59.50    197400.0\n",
       " 1998-01-30    59.50   59.500  58.7500     58.94    152500.0\n",
       " 1998-02-02    59.56   60.250  59.5600     60.25    273600.0\n",
       " 1998-02-03    60.25   60.940  59.6900     60.94    136600.0\n",
       " 1998-02-04    60.69   60.690  59.8800     60.12    328600.0\n",
       " 1998-02-05    60.25   60.380  59.4400     60.19    124200.0\n",
       " 1998-02-06    60.38   61.940  60.3800     61.88    217300.0\n",
       " 1998-02-09    61.75   61.940  61.1900     61.94    133000.0\n",
       " 1998-02-10    61.94   62.440  61.9400     62.12    164600.0\n",
       " 1998-02-11    62.12   62.310  61.7500     62.00     75900.0\n",
       " 1998-02-12    61.81   62.060  61.2500     61.88    126100.0\n",
       " 1998-02-13    61.88   62.310  61.8800     62.06    111000.0\n",
       " ...             ...      ...      ...       ...         ...\n",
       " 2018-12-06    47.56   48.180  46.9100     48.14   6818633.0\n",
       " 2018-12-07    48.15   48.670  47.3200     47.66   5524530.0\n",
       " 2018-12-10    47.60   47.660  46.2500     46.95   5942833.0\n",
       " 2018-12-11    47.31   47.685  46.2600     46.56   4734211.0\n",
       " 2018-12-12    47.10   47.370  46.6600     46.82   4394718.0\n",
       " 2018-12-13    46.92   47.015  45.8000     46.02   4718687.0\n",
       " 2018-12-14    45.69   46.400  45.5850     45.66   5380992.0\n",
       " 2018-12-17    45.43   45.955  44.9400     45.15   4858977.0\n",
       " 2018-12-18    45.24   45.470  43.8928     44.16   5398224.0\n",
       " 2018-12-19    44.01   44.500  42.9600     43.30   6380711.0\n",
       " 2018-12-20    42.78   43.550  42.7100     43.19   7860421.0\n",
       " 2018-12-21    42.88   43.730  42.2600     42.38   9199049.0\n",
       " 2018-12-24    42.07   42.420  41.2500     41.27   3378956.0\n",
       " 2018-12-26    41.28   42.830  40.6800     42.83   5577547.0\n",
       " 2018-12-27    42.31   42.980  41.4800     42.98   6295508.0\n",
       " 2018-12-28    43.11   43.490  42.6100     42.95   4593560.0\n",
       " 2018-12-31    43.01   43.450  42.6400     43.32   3694095.0\n",
       " 2019-01-02    42.86   44.450  42.7900     44.39   4831912.0\n",
       " 2019-01-03    44.22   44.790  43.9600     44.09   3530604.0\n",
       " 2019-01-04    44.87   45.420  44.7000     45.25   3267164.0\n",
       " 2019-01-07    45.13   46.040  44.8600     45.61   3584381.0\n",
       " 2019-01-08    45.79   45.960  45.0700     45.72   3389345.0\n",
       " 2019-01-09    45.84   46.290  45.6200     46.15   5826951.0\n",
       " 2019-01-10    45.20   46.140  45.2000     45.86   6726848.0\n",
       " 2019-01-11    44.83   45.760  44.7800     45.61  11337051.0\n",
       " 2019-01-14    45.20   46.350  45.2000     46.15   9035417.0\n",
       " 2019-01-15    46.02   46.390  45.5400     46.34   6512927.0\n",
       " 2019-01-16    46.78   47.845  46.5600     47.54   7020043.0\n",
       " 2019-01-17    46.75   48.450  46.5500     48.28   5811600.0\n",
       " 2019-01-18    48.49   49.410  48.1900     49.29   5214575.0\n",
       " \n",
       " [5296 rows x 5 columns],\n",
       " 'metadata': {'1. Information': 'Daily Prices (open, high, low, close) and Volumes',\n",
       "  '2. Symbol': 'BBT',\n",
       "  '3. Last Refreshed': '2019-01-18',\n",
       "  '4. Output Size': 'Full size',\n",
       "  '5. Time Zone': 'US/Eastern'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import argparse\n",
    "import quandl\n",
    "import pandas_datareader as web\n",
    "from time import sleep\n",
    "import datetime as dt\n",
    "import sys\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.techindicators import TechIndicators\n",
    "from alpha_vantage.sectorperformance import SectorPerformances\n",
    "from alpha_vantage.cryptocurrencies import CryptoCurrencies\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "RAW_DATA_DIR = 'raw_data'\n",
    "def load_dataset_from_disk(save_dir):\n",
    "    with open(os.path.join(save_dir, \"BBT\"), 'rb') as f:\n",
    "        transformers = pickle.load(f)\n",
    "    return transformers\n",
    "\n",
    "carl=load_dataset_from_disk(RAW_DATA_DIR)\n",
    "carl.keys() #(['data', 'metadata'])\n",
    "carl[\"data\"]\n",
    "# carl[\"metadata\"][]\n",
    "carl[\"metadata\"].keys()\n",
    "carl[\"metadata\"]\n",
    "carl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/505) Getting data for MMM...\n",
      "Symbol MMM already downloaded. Skipping...\n",
      "(1/505) Getting data for AOS...\n",
      "Symbol AOS already downloaded. Skipping...\n",
      "(2/505) Getting data for ABT...\n",
      "Symbol ABT already downloaded. Skipping...\n",
      "(3/505) Getting data for ABBV...\n",
      "Symbol ABBV already downloaded. Skipping...\n",
      "(4/505) Getting data for ACN...\n",
      "Symbol ACN already downloaded. Skipping...\n",
      "(5/505) Getting data for ATVI...\n",
      "Symbol ATVI already downloaded. Skipping...\n",
      "(6/505) Getting data for AYI...\n",
      "Symbol AYI already downloaded. Skipping...\n",
      "(7/505) Getting data for ADBE...\n",
      "Symbol ADBE already downloaded. Skipping...\n",
      "(8/505) Getting data for AAP...\n",
      "Symbol AAP already downloaded. Skipping...\n",
      "(9/505) Getting data for AMD...\n",
      "Symbol AMD already downloaded. Skipping...\n",
      "(10/505) Getting data for AES...\n",
      "Symbol AES already downloaded. Skipping...\n",
      "(11/505) Getting data for AET...\n",
      "Symbol AET already downloaded. Skipping...\n",
      "(12/505) Getting data for AMG...\n",
      "Symbol AMG already downloaded. Skipping...\n",
      "(13/505) Getting data for AFL...\n",
      "Symbol AFL already downloaded. Skipping...\n",
      "(14/505) Getting data for A...\n",
      "Symbol A already downloaded. Skipping...\n",
      "(15/505) Getting data for APD...\n",
      "Symbol APD already downloaded. Skipping...\n",
      "(16/505) Getting data for AKAM...\n",
      "Symbol AKAM already downloaded. Skipping...\n",
      "(17/505) Getting data for ALK...\n",
      "Symbol ALK already downloaded. Skipping...\n",
      "(18/505) Getting data for ALB...\n",
      "Symbol ALB already downloaded. Skipping...\n",
      "(19/505) Getting data for ARE...\n",
      "Symbol ARE already downloaded. Skipping...\n",
      "(20/505) Getting data for ALXN...\n",
      "Symbol ALXN already downloaded. Skipping...\n",
      "(21/505) Getting data for ALGN...\n",
      "Symbol ALGN already downloaded. Skipping...\n",
      "(22/505) Getting data for ALLE...\n",
      "Symbol ALLE already downloaded. Skipping...\n",
      "(23/505) Getting data for AGN...\n",
      "Symbol AGN already downloaded. Skipping...\n",
      "(24/505) Getting data for ADS...\n",
      "Symbol ADS already downloaded. Skipping...\n",
      "(25/505) Getting data for LNT...\n",
      "Symbol LNT already downloaded. Skipping...\n",
      "(26/505) Getting data for ALL...\n",
      "Symbol ALL already downloaded. Skipping...\n",
      "(27/505) Getting data for GOOGL...\n",
      "Symbol GOOGL already downloaded. Skipping...\n",
      "(28/505) Getting data for GOOG...\n",
      "Symbol GOOG already downloaded. Skipping...\n",
      "(29/505) Getting data for MO...\n",
      "Symbol MO already downloaded. Skipping...\n",
      "(30/505) Getting data for AMZN...\n",
      "Symbol AMZN already downloaded. Skipping...\n",
      "(31/505) Getting data for AEE...\n",
      "Symbol AEE already downloaded. Skipping...\n",
      "(32/505) Getting data for AAL...\n",
      "Symbol AAL already downloaded. Skipping...\n",
      "(33/505) Getting data for AEP...\n",
      "Symbol AEP already downloaded. Skipping...\n",
      "(34/505) Getting data for AXP...\n",
      "Symbol AXP already downloaded. Skipping...\n",
      "(35/505) Getting data for AIG...\n",
      "Symbol AIG already downloaded. Skipping...\n",
      "(36/505) Getting data for AMT...\n",
      "Symbol AMT already downloaded. Skipping...\n",
      "(37/505) Getting data for AWK...\n",
      "Symbol AWK already downloaded. Skipping...\n",
      "(38/505) Getting data for AMP...\n",
      "Symbol AMP already downloaded. Skipping...\n",
      "(39/505) Getting data for ABC...\n",
      "Symbol ABC already downloaded. Skipping...\n",
      "(40/505) Getting data for AME...\n",
      "Symbol AME already downloaded. Skipping...\n",
      "(41/505) Getting data for AMGN...\n",
      "Symbol AMGN already downloaded. Skipping...\n",
      "(42/505) Getting data for APH...\n",
      "Symbol APH already downloaded. Skipping...\n",
      "(43/505) Getting data for APC...\n",
      "Symbol APC already downloaded. Skipping...\n",
      "(44/505) Getting data for ADI...\n",
      "Symbol ADI already downloaded. Skipping...\n",
      "(45/505) Getting data for ANDV...\n",
      "Symbol ANDV already downloaded. Skipping...\n",
      "(46/505) Getting data for ANSS...\n",
      "Symbol ANSS already downloaded. Skipping...\n",
      "(47/505) Getting data for ANTM...\n",
      "Symbol ANTM already downloaded. Skipping...\n",
      "(48/505) Getting data for AON...\n",
      "Symbol AON already downloaded. Skipping...\n",
      "(49/505) Getting data for APA...\n",
      "Symbol APA already downloaded. Skipping...\n",
      "(50/505) Getting data for AIV...\n",
      "Symbol AIV already downloaded. Skipping...\n",
      "(51/505) Getting data for AAPL...\n",
      "Symbol AAPL already downloaded. Skipping...\n",
      "(52/505) Getting data for AMAT...\n",
      "Symbol AMAT already downloaded. Skipping...\n",
      "(53/505) Getting data for APTV...\n",
      "Symbol APTV already downloaded. Skipping...\n",
      "(54/505) Getting data for ADM...\n",
      "Symbol ADM already downloaded. Skipping...\n",
      "(55/505) Getting data for ARNC...\n",
      "Symbol ARNC already downloaded. Skipping...\n",
      "(56/505) Getting data for AJG...\n",
      "Symbol AJG already downloaded. Skipping...\n",
      "(57/505) Getting data for AIZ...\n",
      "Symbol AIZ already downloaded. Skipping...\n",
      "(58/505) Getting data for T...\n",
      "Symbol T already downloaded. Skipping...\n",
      "(59/505) Getting data for ADSK...\n",
      "Symbol ADSK already downloaded. Skipping...\n",
      "(60/505) Getting data for ADP...\n",
      "Symbol ADP already downloaded. Skipping...\n",
      "(61/505) Getting data for AZO...\n",
      "(62/505) Getting data for AVB...\n",
      "(63/505) Getting data for AVY...\n",
      "(64/505) Getting data for BHGE...\n",
      "(65/505) Getting data for BLL...\n"
     ]
    }
   ],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import ta\n",
    "import time\n",
    "\n",
    "\n",
    "def MA5(df):\n",
    "    return ta.MA(df, 5)\n",
    "\n",
    "\n",
    "def MA10(df):\n",
    "    return ta.MA(df, 10)\n",
    "\n",
    "\n",
    "def EMA20(df):\n",
    "    return ta.EMA(df, 20)\n",
    "\n",
    "\n",
    "def ROC(df):\n",
    "    return ta.ROC(df, 5)\n",
    "\n",
    "\n",
    "def ATR(df):\n",
    "    return ta.ATR(df, 10)\n",
    "\n",
    "\n",
    "def BBANDS(df):\n",
    "    return ta.BBANDS(df, 20)\n",
    "\n",
    "\n",
    "def ADX(df):\n",
    "    return ta.ADX(df, 10, 5)\n",
    "\n",
    "\n",
    "def MACD(df):\n",
    "    return ta.MACD(df, 5, 20)\n",
    "\n",
    "\n",
    "def RSI(df):\n",
    "    return ta.RSI(df, 10)\n",
    "\n",
    "\n",
    "def MFI(df):\n",
    "    return ta.MFI(df, 10)\n",
    "\n",
    "\n",
    "def CCI(df):\n",
    "    return ta.CCI(df, 10)\n",
    "\n",
    "\n",
    "def KELCH(df):\n",
    "    return ta.KELCH(df, 20)\n",
    "\n",
    "\n",
    "indicators = [MA5, MA10, EMA20, ROC, ATR, BBANDS, ta.PPSR, ta.STOK,\n",
    "              ADX, MACD, RSI, MFI, CCI, KELCH]\n",
    "\n",
    "NB_FEATURES = 30\n",
    "\n",
    "API_KEY = '9CRTS3F0KI6FJU95'\n",
    "\n",
    "SYM_FILE = 'S&p500companies.csv'\n",
    "RAW_DATA_DIR = 'raw_data'\n",
    "TRAIN_DATA_DIR = 'data'\n",
    "WINDOW_SIZE = 60\n",
    "\n",
    "TS = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "\n",
    "\n",
    "def get_syms():\n",
    "    syms = []\n",
    "    with open(SYM_FILE) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            syms.append(row[0])\n",
    "    return syms\n",
    "\n",
    "\n",
    "def load_sym(sym):\n",
    "    with open(os.path.join(RAW_DATA_DIR, sym)) as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def split(inputs, window=WINDOW_SIZE):\n",
    "    n = len(inputs)\n",
    "    indices = np.arange(window, n, window)\n",
    "    split_inputs = np.split(inputs[:indices[-2]], indices[:-2])\n",
    "    labels = inputs['Low'].ix[indices[1:]].as_matrix()\\\n",
    "        > inputs['High'].ix[indices[:-1]].as_matrix()\n",
    "    assert len(split_inputs) == len(labels)\n",
    "    return split_inputs, labels\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    data = data.rename(index=str, columns={x: x[3:].capitalize() for x in\n",
    "                                           data.columns})\n",
    "    data['Volume'] = np.log(1 + data['Volume'])\n",
    "    data.index = range(len(data.index))\n",
    "    for indicator in indicators:\n",
    "        data = indicator(data)\n",
    "    data = data.shift(-WINDOW_SIZE)[:-WINDOW_SIZE]\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_all_data_and_save(window=WINDOW_SIZE, nb_features=NB_FEATURES):\n",
    "    all_inputs = []\n",
    "    all_labels = []\n",
    "    for sym in os.listdir(RAW_DATA_DIR):\n",
    "        if sym[0] != '.':\n",
    "            data = load_sym(sym)\n",
    "            if 'data' in data:\n",
    "                inputs = preprocess(data['data'])\n",
    "                if inputs.shape[0] > 2 * window:\n",
    "                    print('Loading data from symbol %s...' % sym)\n",
    "                    inputs, labels = split(inputs, window=window)\n",
    "                    all_inputs.extend(inputs)\n",
    "                    all_labels.append(labels)\n",
    "    all_inputs = np.concatenate(all_inputs).reshape(-1, window, nb_features)\n",
    "    all_labels = np.concatenate(all_labels).reshape(-1, 1)\n",
    "    print(all_inputs.shape)\n",
    "    print(all_labels.shape)\n",
    "    assert all_inputs.shape[0] == all_labels.shape[0]\n",
    "    with open(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_inputs, f)\n",
    "    with open(os.path.join(TRAIN_DATA_DIR, 'all_labels.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_labels, f)\n",
    "    return all_inputs, all_labels\n",
    "\n",
    "\n",
    "def split_train_dev_test_to_file(inputs=None, labels=None):\n",
    "    if inputs is None:\n",
    "        with open(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl'), 'rb') as f:\n",
    "            inputs = pickle.load(f)\n",
    "    if labels is None:\n",
    "        with open(os.path.join(TRAIN_DATA_DIR, 'all_labels.pkl'), 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "    n = inputs.shape[0]\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    indices = np.random.permutation(n)\n",
    "    train_idx, eval_idx, test_idx = \\\n",
    "        indices[:int(0.9*n)], indices[int(0.9*n):int(0.95*n)], \\\n",
    "        indices[int(0.95*n):]\n",
    "    pickle.dump(inputs[train_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'train_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(inputs[eval_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'eval_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(inputs[test_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'test_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(labels[train_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'train_labels.pkl'), 'wb'))\n",
    "    pickle.dump(labels[eval_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'eval_labels.pkl'), 'wb'))\n",
    "    pickle.dump(labels[test_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'test_labels.pkl'), 'wb'))\n",
    "\n",
    "\n",
    "def get_sym_and_save(sym):\n",
    "    if os.path.exists(os.path.join(RAW_DATA_DIR, sym)):\n",
    "        print('Symbol %s already downloaded. Skipping...' % sym)\n",
    "        return\n",
    "    try:\n",
    "        time.sleep(60)\n",
    "        data, metadata = TS.get_daily(symbol=sym, outputsize='full')\n",
    "    except ValueError:\n",
    "        print('Symbol %s does not exist! Skipping...' % sym)\n",
    "        with open(os.path.join(RAW_DATA_DIR, sym), 'wb') as f:\n",
    "            pickle.dump({}, f)\n",
    "        return\n",
    "    with open(os.path.join(RAW_DATA_DIR, sym), 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'data': data,\n",
    "            'metadata': metadata\n",
    "        }, f)\n",
    "\n",
    "\n",
    "def get_all_raw_data(interval='5min'):\n",
    "    syms = get_syms()\n",
    "    for i, sym in enumerate(syms):\n",
    "        print('(%d/%d) Getting data for %s...' % (i, len(syms), sym))\n",
    "        get_sym_and_save(sym)\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl')) \\\n",
    "            or not os.path.exists(os.path.join(TRAIN_DATA_DIR,\n",
    "                                               'all_labels.pkl')):\n",
    "        get_all_raw_data()\n",
    "        split_all_data_and_save()\n",
    "    split_train_dev_test_to_file()\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = data.rename(index=str, columns={x: x[3:].capitalize() for x in\n",
    "                                           data.columns})\n",
    "    data['Volume'] = np.log(1 + data['Volume'])\n",
    "    data.index = range(len(data.index))\n",
    "    for indicator in indicators:\n",
    "        data = indicator(data)\n",
    "    data = data.shift(-WINDOW_SIZE)[:-WINDOW_SIZE]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Volume'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Volume'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-095cf75a5481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-dcad2a459779>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m     data = data.rename(index=str, columns={x: x[3:].capitalize() for x in\n\u001b[1;32m      3\u001b[0m                                            data.columns})\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindicators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Volume'"
     ]
    }
   ],
   "source": [
    "# preprocess(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
