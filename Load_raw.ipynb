{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data':             1. open  2. high   3. low  4. close   5. volume\n",
       " date                                                       \n",
       " 1998-01-02    63.56   63.620  62.5600     63.12    202600.0\n",
       " 1998-01-05    63.00   63.190  62.5600     62.94    258100.0\n",
       " 1998-01-06    62.69   62.750  62.0000     62.25    302800.0\n",
       " 1998-01-07    62.00   62.000  60.5000     61.38    313300.0\n",
       " 1998-01-08    61.38   61.380  59.8100     60.38    253500.0\n",
       " 1998-01-09    60.00   60.380  59.4400     59.56    491500.0\n",
       " 1998-01-12    58.00   59.190  58.0000     59.00    400200.0\n",
       " 1998-01-13    59.00   60.000  58.9400     59.81    182600.0\n",
       " 1998-01-14    59.94   60.190  59.5000     60.19    158100.0\n",
       " 1998-01-15    60.00   60.310  59.5000     59.50    155200.0\n",
       " 1998-01-16    59.50   59.810  59.4400     59.56    247300.0\n",
       " 1998-01-20    59.56   60.000  59.5600     60.00    223800.0\n",
       " 1998-01-21    60.00   60.000  58.7500     59.19    156700.0\n",
       " 1998-01-22    59.00   59.000  58.1200     58.44    200700.0\n",
       " 1998-01-23    58.62   58.810  57.8800     58.06    186100.0\n",
       " 1998-01-26    58.19   58.940  58.0000     58.31    131800.0\n",
       " 1998-01-27    58.25   59.250  58.2500     58.88    174100.0\n",
       " 1998-01-28    59.12   59.500  58.5000     59.50    161900.0\n",
       " 1998-01-29    59.00   60.250  59.0000     59.50    197400.0\n",
       " 1998-01-30    59.50   59.500  58.7500     58.94    152500.0\n",
       " 1998-02-02    59.56   60.250  59.5600     60.25    273600.0\n",
       " 1998-02-03    60.25   60.940  59.6900     60.94    136600.0\n",
       " 1998-02-04    60.69   60.690  59.8800     60.12    328600.0\n",
       " 1998-02-05    60.25   60.380  59.4400     60.19    124200.0\n",
       " 1998-02-06    60.38   61.940  60.3800     61.88    217300.0\n",
       " 1998-02-09    61.75   61.940  61.1900     61.94    133000.0\n",
       " 1998-02-10    61.94   62.440  61.9400     62.12    164600.0\n",
       " 1998-02-11    62.12   62.310  61.7500     62.00     75900.0\n",
       " 1998-02-12    61.81   62.060  61.2500     61.88    126100.0\n",
       " 1998-02-13    61.88   62.310  61.8800     62.06    111000.0\n",
       " ...             ...      ...      ...       ...         ...\n",
       " 2018-12-06    47.56   48.180  46.9100     48.14   6818633.0\n",
       " 2018-12-07    48.15   48.670  47.3200     47.66   5524530.0\n",
       " 2018-12-10    47.60   47.660  46.2500     46.95   5942833.0\n",
       " 2018-12-11    47.31   47.685  46.2600     46.56   4734211.0\n",
       " 2018-12-12    47.10   47.370  46.6600     46.82   4394718.0\n",
       " 2018-12-13    46.92   47.015  45.8000     46.02   4718687.0\n",
       " 2018-12-14    45.69   46.400  45.5850     45.66   5380992.0\n",
       " 2018-12-17    45.43   45.955  44.9400     45.15   4858977.0\n",
       " 2018-12-18    45.24   45.470  43.8928     44.16   5398224.0\n",
       " 2018-12-19    44.01   44.500  42.9600     43.30   6380711.0\n",
       " 2018-12-20    42.78   43.550  42.7100     43.19   7860421.0\n",
       " 2018-12-21    42.88   43.730  42.2600     42.38   9199049.0\n",
       " 2018-12-24    42.07   42.420  41.2500     41.27   3378956.0\n",
       " 2018-12-26    41.28   42.830  40.6800     42.83   5577547.0\n",
       " 2018-12-27    42.31   42.980  41.4800     42.98   6295508.0\n",
       " 2018-12-28    43.11   43.490  42.6100     42.95   4593560.0\n",
       " 2018-12-31    43.01   43.450  42.6400     43.32   3694095.0\n",
       " 2019-01-02    42.86   44.450  42.7900     44.39   4831912.0\n",
       " 2019-01-03    44.22   44.790  43.9600     44.09   3530604.0\n",
       " 2019-01-04    44.87   45.420  44.7000     45.25   3267164.0\n",
       " 2019-01-07    45.13   46.040  44.8600     45.61   3584381.0\n",
       " 2019-01-08    45.79   45.960  45.0700     45.72   3389345.0\n",
       " 2019-01-09    45.84   46.290  45.6200     46.15   5826951.0\n",
       " 2019-01-10    45.20   46.140  45.2000     45.86   6726848.0\n",
       " 2019-01-11    44.83   45.760  44.7800     45.61  11337051.0\n",
       " 2019-01-14    45.20   46.350  45.2000     46.15   9035417.0\n",
       " 2019-01-15    46.02   46.390  45.5400     46.34   6512927.0\n",
       " 2019-01-16    46.78   47.845  46.5600     47.54   7020043.0\n",
       " 2019-01-17    46.75   48.450  46.5500     48.28   5811600.0\n",
       " 2019-01-18    48.49   49.410  48.1900     49.29   5214575.0\n",
       " \n",
       " [5296 rows x 5 columns],\n",
       " 'metadata': {'1. Information': 'Daily Prices (open, high, low, close) and Volumes',\n",
       "  '2. Symbol': 'BBT',\n",
       "  '3. Last Refreshed': '2019-01-18',\n",
       "  '4. Output Size': 'Full size',\n",
       "  '5. Time Zone': 'US/Eastern'}}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import argparse\n",
    "import quandl\n",
    "import pandas_datareader as web\n",
    "from time import sleep\n",
    "import datetime as dt\n",
    "import sys\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.techindicators import TechIndicators\n",
    "from alpha_vantage.sectorperformance import SectorPerformances\n",
    "from alpha_vantage.cryptocurrencies import CryptoCurrencies\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "RAW_DATA_DIR = 'raw_data'\n",
    "def load_dataset_from_disk(save_dir):\n",
    "    with open(os.path.join(save_dir, \"BBT\"), 'rb') as f:\n",
    "        transformers = pickle.load(f)\n",
    "    return transformers\n",
    "\n",
    "carl=load_dataset_from_disk(RAW_DATA_DIR)\n",
    "carl.keys() #(['data', 'metadata'])\n",
    "carl[\"data\"]\n",
    "# carl[\"metadata\"][]\n",
    "carl[\"metadata\"].keys()\n",
    "carl[\"metadata\"]\n",
    "carl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import ta\n",
    "import time\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-6d10abac2645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-131-6d10abac2645>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mget_all_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0msplit_all_data_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0msplit_train_dev_test_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-131-6d10abac2645>\u001b[0m in \u001b[0;36msplit_train_dev_test_to_file\u001b[0;34m(inputs, labels)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'all_labels.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import ta\n",
    "import time\n",
    "\n",
    "\n",
    "def MA5(df):\n",
    "    return ta.MA(df, 5)\n",
    "def MA10(df):\n",
    "    return ta.MA(df, 10)\n",
    "def EMA20(df):\n",
    "    return ta.EMA(df, 20)\n",
    "def ROC(df):\n",
    "    return ta.ROC(df, 5)\n",
    "def ATR(df):\n",
    "    return ta.ATR(df, 10)\n",
    "def BBANDS(df):\n",
    "    return ta.BBANDS(df, 20)\n",
    "def ADX(df):\n",
    "    return ta.ADX(df, 10, 5)\n",
    "def MACD(df):\n",
    "    return ta.MACD(df, 5, 20)\n",
    "def RSI(df):\n",
    "    return ta.RSI(df, 10)\n",
    "def MFI(df):\n",
    "    return ta.MFI(df, 10)\n",
    "def CCI(df):\n",
    "    return ta.CCI(df, 10)\n",
    "def KELCH(df):\n",
    "    return ta.KELCH(df, 20)\n",
    "\n",
    "\n",
    "indicators = [MA5, MA10, EMA20, ROC, ATR, BBANDS, ta.PPSR, ta.STOK,\n",
    "              ADX, MACD, RSI, MFI, CCI, KELCH]\n",
    "\n",
    "NB_FEATURES = 30\n",
    "\n",
    "API_KEY = 'TZZ9RPNH9YGP8SXX'\n",
    "# Your premium API key for 30 API calls per minute is: TZZ9RPNH9YGP8SXX\n",
    "\n",
    "SYM_FILE = 'S&p500companies.csv'\n",
    "RAW_DATA_DIR = 'raw_data'\n",
    "TRAIN_DATA_DIR = 'data'\n",
    "WINDOW_SIZE = 60\n",
    "\n",
    "TS = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "\n",
    "def get_syms():\n",
    "    syms = []\n",
    "    with open(SYM_FILE) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            syms.append(row[0])\n",
    "    return syms\n",
    "\n",
    "\n",
    "def load_sym(sym):\n",
    "    with open(os.path.join(RAW_DATA_DIR, sym),\"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def split(inputs, window=WINDOW_SIZE):\n",
    "    n = len(inputs)\n",
    "    indices = np.arange(window, n, window)\n",
    "    split_inputs = np.split(inputs[:indices[-2]], indices[:-2])\n",
    "    labels = inputs['Low'].ix[indices[1:]].as_matrix()\\\n",
    "        > inputs['High'].ix[indices[:-1]].as_matrix()\n",
    "    assert len(split_inputs) == len(labels)\n",
    "    return split_inputs, labels\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    data = data.rename(index=str, columns={x: x[3:].capitalize() for x in\n",
    "                                           data.columns})\n",
    "    data['Volume'] = np.log(1 + data['Volume'])\n",
    "    data.index = range(len(data.index))\n",
    "    for indicator in indicators:\n",
    "        data = indicator(data)\n",
    "    data = data.shift(-WINDOW_SIZE)[:-WINDOW_SIZE]\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_all_data_and_save(window=WINDOW_SIZE, nb_features=NB_FEATURES):\n",
    "    all_inputs = []\n",
    "    all_labels = []\n",
    "    for sym in os.listdir(RAW_DATA_DIR)[0:503]:\n",
    "        if sym[0] != '.':\n",
    "            if 'data' in data:\n",
    "                inputs = preprocess(data['data'])\n",
    "                if inputs.shape[0] > 2 * window:\n",
    "                    print('Loading data from symbol %s...' % sym)\n",
    "                    inputs, labels = split(inputs, window=window)\n",
    "                    all_inputs.extend(inputs)\n",
    "                    all_labels.append(labels)\n",
    "    all_inputs = np.concatenate(all_inputs).reshape(-1, window, nb_features)\n",
    "    all_labels = np.concatenate(all_labels).reshape(-1, 1)\n",
    "    print(all_inputs.shape)\n",
    "    print(all_labels.shape)\n",
    "    assert all_inputs.shape[0] == all_labels.shape[0]\n",
    "    with open(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_inputs, f)\n",
    "    with open(os.path.join(TRAIN_DATA_DIR, 'all_labels.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_labels, f)\n",
    "    return all_inputs, all_labels\n",
    "\n",
    "\n",
    "def split_train_dev_test_to_file(inputs=None, labels=None):\n",
    "    if inputs is None:\n",
    "        with open(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl'), 'rb') as f:\n",
    "            inputs = pickle.load(f)\n",
    "    if labels is None:\n",
    "        with open(os.path.join(TRAIN_DATA_DIR, 'all_labels.pkl'), 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "    n = inputs.shape[0]\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    indices = np.random.permutation(n)\n",
    "    train_idx, eval_idx, test_idx = \\\n",
    "        indices[:int(0.9*n)], indices[int(0.9*n):int(0.95*n)], \\\n",
    "        indices[int(0.95*n):]\n",
    "    pickle.dump(inputs[train_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'train_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(inputs[eval_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'eval_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(inputs[test_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'test_inputs.pkl'), 'wb'))\n",
    "    pickle.dump(labels[train_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'train_labels.pkl'), 'wb'))\n",
    "    pickle.dump(labels[eval_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'eval_labels.pkl'), 'wb'))\n",
    "    pickle.dump(labels[test_idx, :],\n",
    "                open(os.path.join(TRAIN_DATA_DIR, 'test_labels.pkl'), 'wb'))\n",
    "\n",
    "\n",
    "def get_sym_and_save(sym):\n",
    "    if os.path.exists(os.path.join(RAW_DATA_DIR, sym)):\n",
    "        print('Symbol %s already downloaded. Skipping...' % sym)\n",
    "        return\n",
    "    try:\n",
    "        data, metadata = TS.get_daily(symbol=sym, outputsize='full')\n",
    "    except ValueError:\n",
    "        print('Symbol %s does not exist! Skipping...' % sym)\n",
    "        with open(os.path.join(RAW_DATA_DIR, sym), 'w') as f:\n",
    "            pickle.dump({}, f)\n",
    "        return\n",
    "    with open(os.path.join(RAW_DATA_DIR, sym), 'w') as f:\n",
    "        pickle.dump({\n",
    "            'data': data,\n",
    "            'metadata': metadata\n",
    "        }, f)\n",
    "\n",
    "\n",
    "def get_all_raw_data(interval='1min'):\n",
    "    syms = get_syms()\n",
    "    for i, sym in enumerate(syms):\n",
    "        print('(%d/%d) Getting data for %s...' % (i, len(syms), sym))\n",
    "        get_sym_and_save(sym)\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(os.path.join(TRAIN_DATA_DIR, 'all_inputs.pkl')) \\\n",
    "            or not os.path.exists(os.path.join(TRAIN_DATA_DIR,\n",
    "                                               'all_labels.pkl')):\n",
    "        get_all_raw_data()\n",
    "        split_all_data_and_save()\n",
    "    split_train_dev_test_to_file()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43258, 60, 30)\n",
      "(43258, 1)\n"
     ]
    }
   ],
   "source": [
    "# split_train_dev_test_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #OLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
